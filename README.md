# Projekt Zastosowania Uczenia Maszynowego

## 1. Informacje ogÃ³lne

| | |
|---|---|
| **Nazwa projektu:** | Klasyfikacja podgatunkÃ³w muzyki elektronicznej (EDM) |
| **Autor:** | Adrian Wiktorowicz |
| **Kierunek, rok i tryb studiÃ³w:** | Informatyka, semestr 3, internetowe |
| **Data oddania projektu:** | 18.01.2026 |

---

## 2. Opis projektu

Celem projektu jest **klasyfikacja 10-sekundowych fragmentÃ³w audio** do jednej z czterech klas podgatunkÃ³w muzyki elektronicznej:

- ðŸ  **House** â€“ Four-on-the-floor beats, soulful vocals
- ðŸ”Š **Techno** â€“ Dark, repetitive, industrial sounds  
- ðŸŒ€ **Trance** â€“ Euphoric melodies, build-ups and breakdowns
- ðŸ¥ **Drum and Bass** â€“ Fast breakbeats (160-180 BPM), heavy bass

Projekt wykorzystuje rÃ³Å¼ne podejÅ›cia do uczenia maszynowego: **klasyczne ML (Random Forest)**, **sieci neuronowe zbudowane od zera (CNN)** oraz **modele transformerowe (AST)** do klasyfikacji na podstawie spektrogramÃ³w mel. MoÅ¼e byÄ‡ uÅ¼yteczny w automatycznym tagowaniu muzyki, systemach rekomendacji oraz analizie trendÃ³w muzycznych.

---

## 3. Dane

| | |
|---|---|
| **Å¹rÃ³dÅ‚o danych:** | MTG-Jamendo Dataset + Jamendo API |
| **Link do metadanych:** | [MTG-Jamendo Dataset](https://github.com/MTG/mtg-jamendo-dataset) |
| **Link do audio API:** | [Jamendo API](https://developer.jamendo.com) |

### Opis danych:

| Parametr | WartoÅ›Ä‡ |
|----------|---------|
| Liczba prÃ³bek | 2517 |
| Liczba klas | 4 (house, techno, trance, drum_and_bass) |
| Format danych | MP3 preview (96 kbps, 10s fragmenty) â†’ Mel spectrogramy |
| PodziaÅ‚ danych | 70% train / 15% val / 15% test |
| Licencja metadanych | CC BY 4.0 |
| Licencja audio | CC BY-NC-SA 3.0 |

> [!NOTE]
> **Uwaga dotyczÄ…ca danych:**
> PeÅ‚ny zbiÃ³r audio **nie jest wrzucony do repozytorium** ze wzglÄ™du na rozmiar i licencjÄ™. Audio pobierane jest dynamicznie z Jamendo API w notebooku `0_Data_Acquisition.ipynb`.

### Przetwarzanie danych:
- Normalizacja tagÃ³w (lowercase, strip)
- Mapowanie synonimÃ³w (np. "dnb" â†’ "drum_and_bass")
- Zachowanie tylko trackÃ³w z **dokÅ‚adnie 1** pasujÄ…cym tagiem (single-label)
- Balansowanie: max 1000 prÃ³bek per klasa
- Artist-disjoint split (ten sam artysta nie wystÄ™puje w rÃ³Å¼nych splitach)

---

## 4. Cel projektu

### Cel biznesowy/badawczy:
- **Co robi model?** Automatycznie klasyfikuje fragmenty audio do jednego z czterech podgatunkÃ³w EDM.
- **Jakie pytanie odpowiada?** Do jakiego podgatunku muzyki elektronicznej naleÅ¼y dany utwÃ³r?
- **Jakie wnioski moÅ¼na wyciÄ…gnÄ…Ä‡?**
  - PorÃ³wnanie skutecznoÅ›ci rÃ³Å¼nych architektur (klasyczne ML vs. CNN vs. Transformery)
  - Analiza trudnoÅ›ci rozrÃ³Å¼niania podobnych podgatunkÃ³w (np. house vs. techno)
  - Ocena przydatnoÅ›ci transfer learningu w audio classification

---

## 5. Struktura projektu

Projekt skÅ‚ada siÄ™ z piÄ™ciu gÅ‚Ã³wnych etapÃ³w, kaÅ¼dy w osobnym notatniku `.ipynb`:

| Etap | Nazwa pliku | Opis |
|------|-------------|------|
| 0 | `0_Data_Acquisition.ipynb` | Pobieranie metadanych i audio z Jamendo API |
| 1 | `1_EDA.ipynb` | Eksploracyjna analiza danych, wizualizacje, wnioski |
| 2 | `2_Preprocessing_Features.ipynb` | Przetwarzanie audio, ekstrakcja cech, spektrogramy mel |
| 3 | `3_Models_Training.ipynb` | Trening modeli: Random Forest, CNN, AST |
| 4 | `4_Evaluation.ipynb` | Ewaluacja, porÃ³wnanie modeli, wizualizacje wynikÃ³w |

---

## 6. Modele

Projekt obejmuje **trzy rÃ³Å¼ne podejÅ›cia** do modelowania danych:

### 6.1 Model klasyczny ML â€“ Random Forest

| | |
|---|---|
| **Algorytm:** | Random Forest Classifier |
| **Liczba drzew:** | 200 |
| **Max gÅ‚Ä™bokoÅ›Ä‡:** | 20 |
| **Min samples split:** | 5 |
| **Cechy wejÅ›ciowe:** | Statystyki ze spektrogramu mel (mean, std, max, min per mel bin) |

**KrÃ³tki opis dziaÅ‚ania:**  
Model uÅ¼ywa statystycznych cech wyekstrahowanych z log-mel spektrogramÃ³w. Dla kaÅ¼dego z 128 mel bins obliczane sÄ… statystyki (Å›rednia, odchylenie, min, max), tworzÄ…c wektor cech 512-wymiarowy. Random Forest podejmuje decyzjÄ™ na podstawie gÅ‚osowania 200 drzew.

**Wyniki:**

| Metryka | WartoÅ›Ä‡ |
|---------|---------|
| Accuracy | 0.3110 (31.10%) |
| Macro F1 | 0.2471 |
| Macro Precision | 0.2406 |
| Macro Recall | 0.2881 |

---

### 6.2 SieÄ‡ neuronowa zbudowana od zera â€“ Simple CNN

| | |
|---|---|
| **Architektura:** | 4-block Convolutional Neural Network |
| **Liczba parametrÃ³w:** | ~200K |

**Struktura warstw:**

| Blok | Operacje | Channels | Dropout |
|------|----------|----------|---------|
| 1 | Conv2d â†’ BatchNorm â†’ ReLU â†’ MaxPool(2) | 1 â†’ 16 | 0.1 |
| 2 | Conv2d â†’ BatchNorm â†’ ReLU â†’ MaxPool(2) | 16 â†’ 32 | 0.2 |
| 3 | Conv2d â†’ BatchNorm â†’ ReLU â†’ MaxPool(2) | 32 â†’ 64 | 0.3 |
| 4 | Conv2d â†’ BatchNorm â†’ ReLU â†’ MaxPool(2) | 64 â†’ 128 | 0.4 |
| FC | Adaptive Avg Pool â†’ Linear â†’ Dropout(0.5) â†’ Linear | 128 â†’ 64 â†’ 4 | 0.5 |

**Funkcje aktywacji:** ReLU  
**Optymalizator:** AdamW (lr=1e-3, weight_decay=1e-4)  
**Epoki:** 30 (early stopping patience=7)  
**Augmentacja:** SpecAugment (freq_mask=10, time_mask=20)

**Wyniki:**

| Metryka | WartoÅ›Ä‡ |
|---------|---------|
| Accuracy | 0.3307 (33.07%) |
| Macro F1 | 0.2668 |
| Macro Precision | 0.2573 |
| Macro Recall | 0.3016 |

---

### 6.3 Model transformerowy (fine-tuning) â€“ Audio Spectrogram Transformer (AST)

| | |
|---|---|
| **Nazwa modelu:** | MIT/ast-finetuned-audioset-10-10-0.4593 |
| **Biblioteka:** | HuggingFace Transformers |
| **Liczba parametrÃ³w:** | ~87M |
| **Strategia fine-tuningu:** | ZamroÅ¼enie encodera + odmroÅ¼enie ostatnich 2 blokÃ³w |

**Zakres dostosowania:**  
- Nowa warstwa klasyfikacji (4 klasy zamiast 527 AudioSet)
- Fine-tuning ostatnich 2 blokÃ³w transformera
- Optymalizator: AdamW (lr=1e-5)
- Warmup: 100 krokÃ³w
- Epoki: 10

**Wyniki:**

| Metryka | WartoÅ›Ä‡ |
|---------|---------|
| Accuracy | **0.5276 (52.76%)** |
| Macro F1 | **0.5563** |
| Macro Precision | 0.5772 |
| Macro Recall | 0.5427 |

---

## 7. Ewaluacja

### UÅ¼yte metryki:
- **Accuracy** â€“ ogÃ³lna poprawnoÅ›Ä‡ klasyfikacji
- **Macro F1** â€“ zbalansowana Å›rednia F1 per klasa (gÅ‚Ã³wna metryka)
- **Macro Precision** â€“ Å›rednia precyzja per klasa
- **Macro Recall** â€“ Å›rednia czuÅ‚oÅ›Ä‡ per klasa

### PorÃ³wnanie modeli:

| Model | Accuracy | Macro F1 | Uwagi |
|-------|----------|----------|-------|
| Random Forest | 0.3110 | 0.2471 | NajsÅ‚abszy â€“ cechy statystyczne niewystarczajÄ…ce |
| CNN | 0.3307 | 0.2668 | Marginalna poprawa wzglÄ™dem RF |
| **AST** | **0.5276** | **0.5563** | **Najlepszy â€“ transfer learning z AudioSet** |

### Wizualizacje (w folderze `results/`):

| Wizualizacja | Plik |
|--------------|------|
| Macierz pomyÅ‚ek â€“ wszystkie modele | `all_confusion_matrices.png` |
| Macierz pomyÅ‚ek â€“ Random Forest | `confusion_matrix_rf.png` |
| Macierz pomyÅ‚ek â€“ CNN | `confusion_matrix_cnn.png` |
| Macierz pomyÅ‚ek â€“ AST | `confusion_matrix_ast.png` |
| Krzywe uczenia â€“ CNN | `cnn_learning_curves.png` |
| Krzywe uczenia â€“ AST | `ast_learning_curves.png` |
| PorÃ³wnanie modeli | `model_comparison.png` |
| F1 per klasa | `per_class_f1.png` |
| Analiza bÅ‚Ä™dÃ³w | `error_analysis.png` |

---

## 8. Wnioski i podsumowanie

### KtÃ³ry model okazaÅ‚ siÄ™ najlepszy i dlaczego?

**Audio Spectrogram Transformer (AST)** osiÄ…gnÄ…Å‚ najlepsze wyniki z Macro F1 = 0.5563, znaczÄ…co przewyÅ¼szajÄ…c modele klasyczne. Wynika to z:
- **Transfer learning** â€“ model pretrenowany na AudioSet (2M prÃ³bek, 527 klas) posiada bogate reprezentacje audio
- **Architektura Transformer** â€“ skuteczne modelowanie dÅ‚ugozasiÄ™gowych zaleÅ¼noÅ›ci w spektrogramach
- **Fine-tuning** â€“ dostosowanie do specyfiki podgatunkÃ³w EDM

### TrudnoÅ›ci podczas pracy:
1. **NakÅ‚adanie siÄ™ podgatunkÃ³w** â€“ EDM subgenres majÄ… wspÃ³lne cechy (4/4 beat, syntetyczne brzmienia)
2. **Single-label constraint** â€“ wiele utworÃ³w pasuje do wiÄ™cej niÅ¼ jednej kategorii
3. **JakoÅ›Ä‡ danych** â€“ preview 96kbps MP3 zamiast peÅ‚nych utworÃ³w
4. **Rozmiar datasetu** â€“ filtrowanie single-label znaczÄ…co zredukowaÅ‚o liczbÄ™ prÃ³bek

### Co moÅ¼na poprawiÄ‡ w przyszÅ‚oÅ›ci?
1. Multi-label classification zamiast single-label
2. WiÄ™kszy i bardziej zbalansowany dataset
3. Ensemble rÃ³Å¼nych modeli
4. Augmentacja audio (pitch shift, time stretch)
5. DÅ‚uÅ¼sze fragmenty audio (30s zamiast 10s)

### Potencjalne zastosowania:
- Automatyczne tagowanie utworÃ³w w serwisach streamingowych
- Systemy rekomendacji muzyki
- Analiza trendÃ³w w muzyce elektronicznej
- Asystent DJ-a do organizacji biblioteki muzycznej

---

## 9. Struktura repozytorium

```
zum_project/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Surowe metadane TSV
â”‚   â”œâ”€â”€ processed/        # Manifest CSV
â”‚   â””â”€â”€ audio/            # Pobrane MP3 (gitignored)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 0_Data_Acquisition.ipynb
â”‚   â”œâ”€â”€ 1_EDA.ipynb
â”‚   â”œâ”€â”€ 2_Preprocessing_Features.ipynb
â”‚   â”œâ”€â”€ 3_Models_Training.ipynb
â”‚   â””â”€â”€ 4_Evaluation.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py         # Konfiguracja i hiperparametry
â”‚   â”œâ”€â”€ data_utils.py     # Pobieranie i przetwarzanie danych
â”‚   â”œâ”€â”€ audio_utils.py    # Przetwarzanie audio
â”‚   â”œâ”€â”€ dataset.py        # PyTorch Dataset
â”‚   â”œâ”€â”€ models.py         # Architektury modeli (CNN, RF, AST)
â”‚   â”œâ”€â”€ training.py       # PÄ™tla treningowa
â”‚   â””â”€â”€ evaluation.py     # Metryki i wizualizacje
â”œâ”€â”€ models/               # Checkpointy modeli (gitignored)
â”œâ”€â”€ results/              # Wyniki i wykresy
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## 10. Technologia i biblioteki

| Kategoria | Technologie |
|-----------|-------------|
| **JÄ™zyk** | Python 3.10+ |
| **Deep Learning** | PyTorch, torchaudio |
| **Transformers** | HuggingFace Transformers (AST) |
| **Klasyczne ML** | scikit-learn (Random Forest) |
| **Przetwarzanie audio** | librosa, torchaudio |
| **Analiza danych** | NumPy, Pandas |
| **Wizualizacja** | Matplotlib, Seaborn, Plotly |

### GÅ‚Ã³wne parametry przetwarzania audio:

| Parametr | WartoÅ›Ä‡ |
|----------|---------|
| Sample rate | 22050 Hz |
| Clip duration | 10 sekund |
| Mel bins | 128 |
| FFT size | 1024 |
| Hop length | 256 |

---

## 11. Instalacja i uruchomienie

### 1. Klonowanie repozytorium

```bash
git clone <repo-url>
cd zum_project
```

### 2. Tworzenie Å›rodowiska wirtualnego

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

### 3. Instalacja zaleÅ¼noÅ›ci

```bash
pip install -r requirements.txt
```


### 4. Uruchomienie notebookÃ³w

```bash
jupyter notebook notebooks/

```

---

## 12. Licencja projektu

| Element | Licencja |
|---------|----------|
| Kod projektu | MIT License |
| Metadane MTG-Jamendo | CC BY 4.0 |
| Audio Jamendo | CC BY-NC-SA 3.0 (tylko do celÃ³w niekomercyjnych) |
